{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"3DCNN RGB architecture_colab.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"N62Cjb4J8dWM"},"source":["# Important:\n","- uncommment pip install keras and tensorflow in library for colab\n","- uncomment the parts below with multiple GPU if we are using multiple GPU"]},{"cell_type":"markdown","metadata":{"id":"ExoGyIJfUaUx"},"source":["# Libraries"]},{"cell_type":"code","metadata":{"id":"Jn-y4VX78dWT","executionInfo":{"status":"ok","timestamp":1619602618475,"user_tz":-600,"elapsed":718,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}}},"source":["def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"COMtKdor9nb9"},"source":["#!pip uninstall keras \n","!pip install keras==2.2.4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ml0a1Cqe_XjI"},"source":["#!pip uninstall tensorflow \n","!pip install tensorflow==1.14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6i_U-dBp8dWU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619602741747,"user_tz":-600,"elapsed":2535,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}},"outputId":"9bf2ed02-1da0-4667-f935-5c23f2fb6c45"},"source":["import numpy as np\n","import os\n","from time import time\n","import cv2\n","\n","from keras.utils import Sequence\n","from keras.utils import np_utils\n","\n","\n","from keras.models import Sequential, Input, Model\n","from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n","from keras.regularizers import l2\n","from keras.layers.core import Lambda\n","\n","\n","import keras.backend as K\n","from keras.callbacks import LearningRateScheduler\n","\n","#from keras.utils import multi_gpu_model  \n","from keras.optimizers import Adam, SGD\n","\n","import tensorflow as tf\n","\n","# import tensorflow as tf\n","# from tensorflow import keras\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Dense\n","# from tensorflow.keras.layers import Dropout\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"AI7Q_0gV8dWV"},"source":["## GPU: no usado"]},{"cell_type":"code","metadata":{"id":"OshT_oYO8dWV","outputId":"c875f640-43c7-4482-dac6-936a67249b96"},"source":["#strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], \n","#                                         cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0', '/replica:0/task:0/device:GPU:1')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"32CZv6l48dWW"},"source":["# Data generator: download and data augmentation"]},{"cell_type":"code","metadata":{"id":"qsdd2p3O8dWY","executionInfo":{"status":"ok","timestamp":1619602750510,"user_tz":-600,"elapsed":904,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}}},"source":["class DataGenerator(Sequence):\n","    \"\"\"Data Generator inherited from keras.utils.Sequence\n","    Args: \n","        directory: the path of data set, and each sub-folder will be assigned to one class\n","        batch_size: the number of data points in each batch\n","        shuffle: whether to shuffle the data per epoch\n","    Note:\n","        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n","    \"\"\"\n","    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n","        # Initialize the params\n","        self.batch_size = batch_size\n","        self.directory = directory\n","        self.shuffle = shuffle\n","        self.data_aug = data_augmentation\n","        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n","        self.X_path, self.Y_dict = self.search_data() \n","        # Print basic statistics information\n","        self.print_stats()\n","        return None\n","        \n","    def search_data(self):\n","        X_path = []\n","        Y_dict = {}\n","        # list all kinds of sub-folders\n","        self.dirs = sorted(os.listdir(self.directory))\n","        one_hots = np_utils.to_categorical(range(len(self.dirs)))\n","        for i,folder in enumerate(self.dirs):\n","            folder_path = os.path.join(self.directory,folder)\n","            for file in os.listdir(folder_path):\n","                file_path = os.path.join(folder_path,file)\n","                # append the each file path, and keep its label  \n","                X_path.append(file_path)\n","                Y_dict[file_path] = one_hots[i]\n","        return X_path, Y_dict\n","    \n","    def print_stats(self):\n","        # calculate basic information\n","        self.n_files = len(self.X_path)\n","        self.n_classes = len(self.dirs)\n","        self.indexes = np.arange(len(self.X_path))\n","        np.random.shuffle(self.indexes)\n","        # Output states\n","        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n","        for i,label in enumerate(self.dirs):\n","            print('%10s : '%(label),i)\n","        return None\n","    \n","    def __len__(self):\n","        # calculate the iterations of each epoch\n","        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n","        return int(steps_per_epoch)\n","\n","    def __getitem__(self, index):\n","        \"\"\"Get the data of each batch\n","        \"\"\"\n","        # get the indexs of each batch\n","        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        # using batch_indexs to get path of current batch\n","        batch_path = [self.X_path[k] for k in batch_indexs]\n","        # get batch data\n","        batch_x, batch_y = self.data_generation(batch_path)\n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        # shuffle the data at each end of epoch\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def data_generation(self, batch_path):\n","        # load data into memory, you can change the np.load to any method you want\n","        batch_x = [self.load_data(x) for x in batch_path]\n","        batch_y = [self.Y_dict[x] for x in batch_path]\n","        # transfer the data format and take one-hot coding for labels\n","        batch_x = np.array(batch_x)\n","        batch_y = np.array(batch_y)\n","        return batch_x, batch_y\n","      \n","    def normalize(self, data):\n","        mean = np.mean(data)\n","        std = np.std(data)\n","        return (data-mean) / std\n","    \n","    def random_flip(self, video, prob):\n","        s = np.random.rand()\n","        if s < prob:\n","            video = np.flip(m=video, axis=2)\n","        return video    \n","    \n","    def uniform_sampling(self, video, target_frames=64):\n","        # get total frames of input video and calculate sampling interval \n","        len_frames = int(len(video))\n","        interval = int(np.ceil(len_frames/target_frames))\n","        # init empty list for sampled video and \n","        sampled_video = []\n","        for i in range(0,len_frames,interval):\n","            sampled_video.append(video[i])     \n","        # calculate numer of padded frames and fix it \n","        num_pad = target_frames - len(sampled_video)\n","        if num_pad>0:\n","            padding = [video[i] for i in range(-num_pad,0)]\n","            sampled_video += padding     \n","        # get sampled video\n","        return np.array(sampled_video, dtype=np.float32)\n","    \n","    def dynamic_crop(self, video):\n","        # extract layer of optical flow from video\n","        opt_flows = video[...,3]\n","        # sum of optical flow magnitude of individual frame\n","        magnitude = np.sum(opt_flows, axis=0)\n","        # filter slight noise by threshold \n","        thresh = np.mean(magnitude)\n","        magnitude[magnitude<thresh] = 0\n","        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n","        x_pdf = np.sum(magnitude, axis=1) + 0.001\n","        y_pdf = np.sum(magnitude, axis=0) + 0.001\n","        # normalize PDF of x and y so that the sum of probs = 1\n","        x_pdf /= np.sum(x_pdf)\n","        y_pdf /= np.sum(y_pdf)\n","        # randomly choose some candidates for x and y \n","        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n","        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n","        # get the mean of x and y coordinates for better robustness\n","        x = int(np.mean(x_points))\n","        y = int(np.mean(y_points))\n","        # avoid to beyond boundaries of array\n","        x = max(56,min(x,167))\n","        y = max(56,min(y,167))\n","        # get cropped video \n","        return video[:,x-56:x+56,y-56:y+56,:]  \n","    \n","    def color_jitter(self,video):\n","        # range of s-component: 0-1\n","        # range of v component: 0-255\n","        s_jitter = np.random.uniform(-0.2,0.2)\n","        v_jitter = np.random.uniform(-30,30)\n","        for i in range(len(video)):\n","            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n","            s = hsv[...,1] + s_jitter\n","            v = hsv[...,2] + v_jitter\n","            s[s<0] = 0\n","            s[s>1] = 1\n","            v[v<0] = 0\n","            v[v>255] = 255\n","            hsv[...,1] = s\n","            hsv[...,2] = v\n","            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n","        return video\n","        \n","    def load_data(self, path):\n","        data = np.load(path, mmap_mode='r')[...,:3]\n","        data = np.float32(data)\n","        # sampling 64 frames uniformly from the entire video\n","        data = self.uniform_sampling(video=data, target_frames=64)\n","        # whether to utilize the data augmentation\n","        if  self.data_aug:\n","            data = self.color_jitter(data)\n","            data = self.random_flip(data, prob=0.5)\n","        # normalize\n","        data = self.normalize(data)\n","        return data"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s_QogkPM8dWc"},"source":["# Build the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6ngxYZp8dWd","executionInfo":{"status":"ok","timestamp":1619602754699,"user_tz":-600,"elapsed":1466,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}},"outputId":"6a11461e-cbd2-4940-a7b8-b8e8d5759ed8"},"source":["inputs = Input(shape=(64,224,224,3))\n","\n","#####################################################\n","rgb = inputs\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","rgb = Conv3D(\n","    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = Conv3D(\n","    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n","rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n","\n","#####################################################\n","x = MaxPooling3D(pool_size=(8,1,1))(rgb)\n","\n","#####################################################\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","x = Conv3D(\n","    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,2,2))(x)\n","\n","x = Conv3D(\n","    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = Conv3D(\n","    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n","x = MaxPooling3D(pool_size=(2,3,3))(x)\n","\n","#####################################################\n","x = Flatten()(x)\n","x = Dense(128,activation='relu')(x)\n","x = Dropout(0.2)(x)\n","x = Dense(32, activation='relu')(x)\n","pred = Dense(2, activation='softmax')(x)\n","\n","model = Model(inputs=inputs, outputs=pred)\n","\n","model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 64, 224, 224, 3)   0         \n","_________________________________________________________________\n","conv3d_1 (Conv3D)            (None, 64, 224, 224, 16)  448       \n","_________________________________________________________________\n","conv3d_2 (Conv3D)            (None, 64, 224, 224, 16)  784       \n","_________________________________________________________________\n","max_pooling3d_1 (MaxPooling3 (None, 64, 112, 112, 16)  0         \n","_________________________________________________________________\n","conv3d_3 (Conv3D)            (None, 64, 112, 112, 16)  2320      \n","_________________________________________________________________\n","conv3d_4 (Conv3D)            (None, 64, 112, 112, 16)  784       \n","_________________________________________________________________\n","max_pooling3d_2 (MaxPooling3 (None, 64, 56, 56, 16)    0         \n","_________________________________________________________________\n","conv3d_5 (Conv3D)            (None, 64, 56, 56, 32)    4640      \n","_________________________________________________________________\n","conv3d_6 (Conv3D)            (None, 64, 56, 56, 32)    3104      \n","_________________________________________________________________\n","max_pooling3d_3 (MaxPooling3 (None, 64, 28, 28, 32)    0         \n","_________________________________________________________________\n","conv3d_7 (Conv3D)            (None, 64, 28, 28, 32)    9248      \n","_________________________________________________________________\n","conv3d_8 (Conv3D)            (None, 64, 28, 28, 32)    3104      \n","_________________________________________________________________\n","max_pooling3d_4 (MaxPooling3 (None, 64, 14, 14, 32)    0         \n","_________________________________________________________________\n","max_pooling3d_5 (MaxPooling3 (None, 8, 14, 14, 32)     0         \n","_________________________________________________________________\n","conv3d_9 (Conv3D)            (None, 8, 14, 14, 64)     18496     \n","_________________________________________________________________\n","conv3d_10 (Conv3D)           (None, 8, 14, 14, 64)     12352     \n","_________________________________________________________________\n","max_pooling3d_6 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n","_________________________________________________________________\n","conv3d_11 (Conv3D)           (None, 4, 7, 7, 64)       36928     \n","_________________________________________________________________\n","conv3d_12 (Conv3D)           (None, 4, 7, 7, 64)       12352     \n","_________________________________________________________________\n","max_pooling3d_7 (MaxPooling3 (None, 2, 3, 3, 64)       0         \n","_________________________________________________________________\n","conv3d_13 (Conv3D)           (None, 2, 3, 3, 128)      73856     \n","_________________________________________________________________\n","conv3d_14 (Conv3D)           (None, 2, 3, 3, 128)      49280     \n","_________________________________________________________________\n","max_pooling3d_8 (MaxPooling3 (None, 1, 1, 1, 128)      0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 32)                4128      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 66        \n","=================================================================\n","Total params: 248,402\n","Trainable params: 248,402\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0JK-tpuQ8dWf"},"source":["### Set the GPUs and make it parallel (Not for Colab)"]},{"cell_type":"code","metadata":{"id":"0GumSpuN8dWf"},"source":["# #only with cuda\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n","\n","\n","# parallel_model = multi_gpu_model(model, gpus=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8yD9Qc_CXlO","executionInfo":{"elapsed":819,"status":"ok","timestamp":1619489135413,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"},"user_tz":-600},"outputId":"07f950f5-d16d-450a-f46d-e236e8732025"},"source":["# from tensorflow.python.client import device_lib\n","\n","# print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 13371964496489561477\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a91538nh8dWf"},"source":["#otra forma\n","#parallel_model = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"], \n","# cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pwMDfSBm8dWe"},"source":["## Callbacks"]},{"cell_type":"code","metadata":{"id":"Nemfh4Fs8dWf","executionInfo":{"status":"ok","timestamp":1619602760002,"user_tz":-600,"elapsed":851,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}}},"source":["def scheduler(epoch):\n","    # Every 10 epochs, the learning rate is reduced to 1/10 of the original\n","    if epoch % 10 == 0 and epoch != 0:\n","        lr = K.get_value(model.optimizer.lr)\n","        K.set_value(model.optimizer.lr, lr * 0.5)\n","    return K.get_value(model.optimizer.lr)\n","\n","reduce_lr = LearningRateScheduler(scheduler)\n","#callbacks_list = [reduce_lr]\n","\n","#with multiple GPU\n","# def scheduler(epoch):\n","#     # Every 10 epochs, the learning rate is reduced to 1/10 of the original\n","#     if epoch % 10 == 0 and epoch != 0:\n","#         lr = K.get_value(parallel_model.optimizer.lr)\n","#         K.set_value(parallel_model.optimizer.lr, lr * 0.5)\n","#     return K.get_value(parallel_model.optimizer.lr)\n","\n","# reduce_lr = LearningRateScheduler(scheduler)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0nfGFAUaShCr"},"source":["## Save the model"]},{"cell_type":"code","metadata":{"id":"ZB5RbWGDShLe","executionInfo":{"status":"ok","timestamp":1619602762861,"user_tz":-600,"elapsed":928,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}}},"source":["from keras.callbacks import ModelCheckpoint, CSVLogger\n","import keras\n","\n","class MyCbk(keras.callbacks.Callback):\n","\n","    def __init__(self, model):\n","         self.model_to_save = model\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.model_to_save.save('Logs/model_at_epoch_%d.h5' % (epoch+1))\n","\n","check_point = MyCbk(model)\n","\n","\n","#filename = 'Logs/ours_log.csv'\n","#csv_logger = CSVLogger(filename, separator=',', append=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3u9n9UbhSrD9","executionInfo":{"status":"ok","timestamp":1619602764977,"user_tz":-600,"elapsed":891,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}}},"source":["callbacks_list = [check_point, reduce_lr]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gbitIzyu8dWg"},"source":["## Model compilling"]},{"cell_type":"code","metadata":{"id":"DbkpNk168dWg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619602767511,"user_tz":-600,"elapsed":864,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}},"outputId":"22042f75-0736-4e4e-8626-b3bedc34f58b"},"source":["adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","#with strategy.scope():\n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#with multiple gpu\n","# adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n","# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","# parallel_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A-B3-9-b8dWg","executionInfo":{"status":"ok","timestamp":1619602770850,"user_tz":-600,"elapsed":875,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}}},"source":["#set parameters\n","num_epochs  = 5\n","num_workers = 16\n","batch_size  = 16"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSPqaentKdPr","executionInfo":{"status":"ok","timestamp":1619602771758,"user_tz":-600,"elapsed":678,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}},"outputId":"4cf6923d-9289-443d-8b8f-53709852c8e3"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pFZfERcoJ8c3"},"source":["# #example with the videos npy format\n","# base_dir = '/content/gdrive/MyDrive/42028/rw2000/new/train'\n","# base_dir2 = '/content/gdrive/MyDrive/42028/rw2000/new/valid'\n","# # train_dir = os.path.join(base_dir, 'fight')\n","# # test_dir = os.path.join(base_dir2, 'no-fight')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-njOmy-8dWh","executionInfo":{"status":"ok","timestamp":1619602775985,"user_tz":-600,"elapsed":1167,"user":{"displayName":"Javiera De La Carrera Garcia","photoUrl":"","userId":"10492300698488700252"}},"outputId":"2bf0d6b1-30b5-444f-c722-18d14a4a43b7"},"source":["#datasets\n","#dataset = 'RWF2000-opt'\n","path_train = '/content/gdrive/MyDrive/42028/Dataset_Split/new/train'\n","path_test = '/content/gdrive/MyDrive/42028/Dataset_Split/new/validation' \n","\n","\n","#/content/sample_data/anscombe.json\n","\n","train_generator = DataGenerator(directory=path_train, \n","                                batch_size=batch_size, \n","                                data_augmentation=True)\n","\n","val_generator = DataGenerator(directory=path_test,\n","                              batch_size=batch_size, \n","                              data_augmentation=False)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Found 1207 files belonging to 2 classes.\n","     Fight :  0\n","  NonFight :  1\n","Found 393 files belonging to 2 classes.\n","     Fight :  0\n","  NonFight :  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1boCjf28dWh","outputId":"8189f4e5-fc86-4723-a58b-9e5c97f82419"},"source":["#start training\n","\n","with tf.device(\"/device:GPU:0\"):\n","  hist = model.fit_generator(\n","      generator=train_generator, \n","      validation_data=val_generator,\n","      callbacks=callbacks_list,\n","      verbose=1, \n","      epochs=num_epochs,\n","      workers=num_workers ,\n","      max_queue_size=8,\n","      steps_per_epoch=len(train_generator),\n","      validation_steps=len(val_generator))\n","  \n","#multiple gpu\n","# hist = parallel_model.fit_generator(\n","#     generator=train_generator, \n","#     validation_data=val_generator,\n","#     callbacks=callbacks_list,\n","#     verbose=1, \n","#     epochs=num_epochs,\n","#     workers=num_workers ,\n","#     max_queue_size=8,\n","#     steps_per_epoch=len(train_generator),\n","#     validation_steps=len(val_generator))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Epoch 1/5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VMIc4mYD8dWh"},"source":["## Look the results"]},{"cell_type":"code","metadata":{"id":"Uv1FCZkJ8dWh"},"source":["acc = hist.hist['acc']\n","val_acc = hist.hist['val_acc']\n","loss = hist.hist['loss']\n","val_loss = hist.hist['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epochs')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","plt.ylabel('cost')\n","plt.xlabel('Epochs')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BoNWAjKeS8V8"},"source":["## Predictions?"]},{"cell_type":"code","metadata":{"id":"WGIIVvZUS7sg"},"source":[""],"execution_count":null,"outputs":[]}]}