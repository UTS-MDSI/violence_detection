{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7acb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Layers\n",
    "from tensorflow.keras.layers import Dropout #\n",
    "from tensorflow.keras.layers import Reshape #\n",
    "from tensorflow.keras.layers import Lambda #\n",
    "from tensorflow.keras.layers import Input #\n",
    "from tensorflow.keras.layers import Conv3D #\n",
    "from tensorflow.keras.layers import Activation #\n",
    "from tensorflow.keras.layers import Add #\n",
    "\n",
    "# Transformations\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Model\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# RGB and FLOW networds\n",
    "from i3d_inception import Inception_Inflated3d\n",
    "\n",
    "#from tensorflow.python.client import device_lib\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from tensorflow.keras.optimizers import SGD\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "#from tensorflow.keras import applications\n",
    "#from tensorflow.keras.preprocessing import image\n",
    "#from tensorflow.keras.preprocessing.image import \n",
    "\n",
    "#from tensorflow.keras import optimizers\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "#Models\n",
    "#from tensorflow.keras.models import Model #\n",
    "#from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "#from tensorflow.keras import models\n",
    "#from tensorflow.keras import optimizers\n",
    "#from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c52ef",
   "metadata": {},
   "source": [
    "# Step 1: Creating input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8559d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "NUM_FRAMES = 79\n",
    "FRAME_HEIGHT = 224\n",
    "FRAME_WIDTH = 224\n",
    "NUM_RGB_CHANNELS = 3\n",
    "NUM_FLOW_CHANNELS = 2\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Parameters\n",
    "dropout_prob = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1792d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb(input_x):\n",
    "    rgb = input_x[...,:3]\n",
    "    return rgb\n",
    "\n",
    "# extract the optical flows (they are 2d vectors, the final 2)\n",
    "def get_opt(input_x):\n",
    "    opt= input_x[...,3:5]\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "359c4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(None,FRAME_HEIGHT,FRAME_WIDTH,NUM_RGB_CHANNELS + NUM_FLOW_CHANNELS))\n",
    "rgb = Lambda(get_rgb,output_shape=None, name = 'rbg_branch')(inputs)\n",
    "opt = Lambda(get_opt,output_shape=None, name = 'opt_branch')(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a844724",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model = Model(inputs = [inputs], outputs = [rgb, opt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94e7651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_1 (InputLayer)                             [(None, None, 224, 224, 5)]      0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "rbg_branch (Lambda)                              (None, None, 224, 224, 3)        0                 input_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "opt_branch (Lambda)                              (None, None, 224, 224, 2)        0                 input_1[0][0]                                     \n",
      "======================================================================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8549a",
   "metadata": {},
   "source": [
    "# Step 2: Creating rgb and flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b2bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_model = Inception_Inflated3d(\n",
    "                include_top=False,\n",
    "                weights='rgb_imagenet_and_kinetics',\n",
    "                input_tensor=None,\n",
    "                input_shape=(None, FRAME_HEIGHT, FRAME_WIDTH, NUM_RGB_CHANNELS), \n",
    "                classes=NUM_CLASSES,\n",
    "                prefix = 'rgb_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3a79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_layers = Dropout(dropout_prob)(rgb_model.output)\n",
    "extra_layers = Conv3D(NUM_CLASSES, (1, 1, 1),\n",
    "                        strides = (1, 1, 1), \n",
    "                        padding = 'same',\n",
    "                        use_bias = False,\n",
    "                        name = 'rgb_Conv3d_6a_1x1')(extra_layers)\n",
    "extra_layers = Reshape((-1, NUM_CLASSES))(extra_layers)\n",
    "extra_layers = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "                        output_shape=lambda s: (s[0], s[2]))(extra_layers)\n",
    "\n",
    "rgb_model = Model(rgb_model.input, extra_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e345107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make only the last two inception modules and top layer trainable\n",
    "for layer in rgb_model.layers[:-20]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816abe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/FusionI3D/i3d_inception.py:100: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 2 input channels.\n",
      "  str(input_shape[-1]) + ' input channels.')\n"
     ]
    }
   ],
   "source": [
    "flow_model = Inception_Inflated3d(\n",
    "                include_top=False,\n",
    "                weights='flow_imagenet_and_kinetics',\n",
    "                input_tensor = None,\n",
    "                input_shape=(None, FRAME_HEIGHT, FRAME_WIDTH, NUM_FLOW_CHANNELS),\n",
    "                classes=NUM_CLASSES,\n",
    "                prefix = 'opt_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785888db",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_layers = Dropout(dropout_prob)(flow_model.output)\n",
    "extra_layers = Conv3D(NUM_CLASSES, (1, 1, 1),\n",
    "                        strides = (1, 1, 1), \n",
    "                        padding = 'same',\n",
    "                        use_bias = False,\n",
    "                        name = 'opt_Conv3d_6a_1x1')(extra_layers)\n",
    "extra_layers = Reshape((-1, NUM_CLASSES))(extra_layers)\n",
    "extra_layers = Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "                        output_shape=lambda s: (s[0], s[2]))(extra_layers)\n",
    "\n",
    "flow_model = Model(flow_model.input, extra_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4fa2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make only the last two inception modules and top layer trainable\n",
    "for layer in flow_model.layers[:-20]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723b143",
   "metadata": {},
   "source": [
    "# Step 3: Merging models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bae57",
   "metadata": {},
   "source": [
    "## RGB part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d674b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding rgb part to final model\n",
    "input_rgb = input_model.get_layer('rbg_branch').output\n",
    "output_rgb = rgb_model(input_rgb)\n",
    "model  = Model(inputs=input_model.input, outputs=[output_rgb, opt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff8041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_1 (InputLayer)                             [(None, None, 224, 224, 5)]      0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "rbg_branch (Lambda)                              (None, None, 224, 224, 3)        0                 input_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "model_1 (Functional)                             (None, 2)                        12296592          rbg_branch[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "opt_branch (Lambda)                              (None, None, 224, 224, 2)        0                 input_1[0][0]                                     \n",
      "======================================================================================================================================================\n",
      "Total params: 12,296,592\n",
      "Trainable params: 2,585,600\n",
      "Non-trainable params: 9,710,992\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e8666e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "   model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c79c86",
   "metadata": {},
   "source": [
    "## Flow part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf4ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_opt = model.get_layer('opt_branch').output\n",
    "output_flow = flow_model(input_opt)\n",
    "model  = Model(inputs=model.input, outputs=[output_flow, output_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "237bba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 224, 2 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_branch (Lambda)             (None, None, 224, 22 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rbg_branch (Lambda)             (None, None, 224, 22 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 2)            12274640    opt_branch[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 2)            12296592    rbg_branch[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,571,232\n",
      "Trainable params: 5,171,200\n",
      "Non-trainable params: 19,400,032\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "becb2690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "   model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d4561",
   "metadata": {},
   "source": [
    "# Step 4: Adding fusion block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e67b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion = Add()(model.output)\n",
    "fusion = Activation('softmax')(fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c1cb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(model.input, fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb39fc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 224, 2 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "opt_branch (Lambda)             (None, None, 224, 22 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rbg_branch (Lambda)             (None, None, 224, 22 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 2)            12274640    opt_branch[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 2)            12296592    rbg_branch[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2)            0           model_2[0][0]                    \n",
      "                                                                 model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2)            0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 24,571,232\n",
      "Trainable params: 5,171,200\n",
      "Non-trainable params: 19,400,032\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303411bc",
   "metadata": {},
   "source": [
    "# Step 5: Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5377fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusioni3ddatagenerator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d2eb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 8\n",
    "path_train = '../datai3d/i3d_light/train/'\n",
    "path_val = '../datai3d/i3d_light/validation/'\n",
    "path_test = '../datai3d/i3d_light/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac72f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1207 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Found 393 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Found 400 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n"
     ]
    }
   ],
   "source": [
    "# Create data generators for training, validation and test\n",
    "train_generator = DataGenerator(directory=path_train,\n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=True,\n",
    "                                data_augmentation=True,\n",
    "                                target_frames = 79,\n",
    "                                crop_dim = (224, 224),\n",
    "                                flip = True)\n",
    "\n",
    "validation_generator = DataGenerator(directory=path_val,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     data_augmentation=False,\n",
    "                                     target_frames = None,\n",
    "                                     crop_dim = (224, 224),\n",
    "                                     flip = False)\n",
    "\n",
    "test_generator = DataGenerator(directory=path_test,\n",
    "                               batch_size=batch_size, \n",
    "                               shuffle = False,\n",
    "                               data_augmentation=False,\n",
    "                               target_frames = None,\n",
    "                               crop_dim = (224, 224),\n",
    "                               flip = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4579bb",
   "metadata": {},
   "source": [
    "# Step 6: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38d94ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 100\n",
    "steps_per_epoch = train_generator.n_files//batch_size\n",
    "validation_steps = validation_generator.n_files//batch_size\n",
    "\n",
    "# Path to store checkpoints\n",
    "filepath = 'checkpoints/weights_fusioni3dfrozen.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3b16012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "# Reduce learning rate by 10x when plateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                 factor=0.1,\n",
    "                                                 patience=5, \n",
    "                                                 min_lr=0.0001,\n",
    "                                                verbose = 1)\n",
    "\n",
    "# Save best model\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=1, \n",
    "                                                save_best_only=True, \n",
    "                                                save_weights_only=False, \n",
    "                                                mode='auto', \n",
    "                                                save_freq='epoch')\n",
    "\n",
    "# Stop after 10 epochs if val loss does not improve\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             restore_best_weights = True, \n",
    "                                             patience = 10, \n",
    "                                             min_delta = 0.01,\n",
    "                                            verbose = 1)\n",
    "\n",
    "callbacks = [reduce_lr, checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ac3ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimiser (SGD with momentum)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.9)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss='CategoricalCrossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "228cc40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 4752s 32s/step - loss: 0.4780 - accuracy: 0.7890 - val_loss: 0.4429 - val_accuracy: 0.7908\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44293, saving model to checkpoints/weights_fusioni3d.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "150/150 [==============================] - 4789s 32s/step - loss: 0.3436 - accuracy: 0.8424 - val_loss: 0.4501 - val_accuracy: 0.7985\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.44293\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 4565s 30s/step - loss: 0.3097 - accuracy: 0.8632 - val_loss: 0.4502 - val_accuracy: 0.8061\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.44293\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 4720s 32s/step - loss: 0.3067 - accuracy: 0.8632 - val_loss: 0.4480 - val_accuracy: 0.7908\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44293\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 4719s 32s/step - loss: 0.2741 - accuracy: 0.8807 - val_loss: 0.4888 - val_accuracy: 0.7832\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.44293\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 4706s 31s/step - loss: 0.3169 - accuracy: 0.8641 - val_loss: 0.4757 - val_accuracy: 0.7959\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44293\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 5027s 34s/step - loss: 0.3053 - accuracy: 0.8732 - val_loss: 0.4250 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.44293 to 0.42502, saving model to checkpoints/weights_fusioni3d.hdf5\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 4845s 32s/step - loss: 0.2330 - accuracy: 0.9016 - val_loss: 0.4244 - val_accuracy: 0.7934\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42502 to 0.42436, saving model to checkpoints/weights_fusioni3d.hdf5\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9016 "
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[8,64,62,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_5/model_2/opt_MaxPool2d_2a_3x3/MaxPool3D (defined at <ipython-input-29-5393525774f5>:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_21909]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5393525774f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       verbose=1)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8,64,62,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_5/model_2/opt_MaxPool2d_2a_3x3/MaxPool3D (defined at <ipython-input-29-5393525774f5>:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_21909]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "# Start training and save history\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_steps,\n",
    "      callbacks = callbacks,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8343b870",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f7514faf5358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history_i3dfusion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Save history of the model\n",
    "import pickle\n",
    "with open('history_i3dfusionfrozen', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dae557",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dad006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download our pretrained model\n",
    "!mkdir checkpoints\n",
    "%cd checkpoints\n",
    "!gdown --id 16iTf2GwsEMufpa2F7ZYTxwdgwf7VXRW9\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('checkpoints/weights_fusioni3dfrozen.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea1eb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = test_generator.n_files//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "380f1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1213s 24s/step - loss: 0.2896 - accuracy: 0.8675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.2895623743534088, 'accuracy': 0.8675000071525574}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator,\n",
    "               steps = test_steps,\n",
    "               return_dict =  True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m70",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m70"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
