{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d28bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from i3d_inception import Inception_Inflated3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f2e2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import MaxPooling3D\n",
    "from keras.layers import AveragePooling3D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import GlobalAveragePooling3D\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "445f556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 79\n",
    "FRAME_HEIGHT = 224\n",
    "FRAME_WIDTH = 224\n",
    "NUM_RGB_CHANNELS = 3\n",
    "NUM_FLOW_CHANNELS = 2\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae592c64",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ac0abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_model = Inception_Inflated3d(\n",
    "                include_top=False,\n",
    "                weights='rgb_imagenet_and_kinetics',\n",
    "                input_shape=(NUM_FRAMES, FRAME_HEIGHT, FRAME_WIDTH, NUM_RGB_CHANNELS),\n",
    "                classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f9f98605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"i3d_inception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 79, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_1a_7x7_conv (Conv3D)     (None, 40, 112, 112, 65856       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_1a_7x7_bn (BatchNormaliz (None, 40, 112, 112, 192         Conv3d_1a_7x7_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_1a_7x7 (Activation)      (None, 40, 112, 112, 0           Conv3d_1a_7x7_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_2a_3x3 (MaxPooling3D) (None, 40, 56, 56, 6 0           Conv3d_1a_7x7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2b_1x1_conv (Conv3D)     (None, 40, 56, 56, 6 4096        MaxPool2d_2a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2b_1x1_bn (BatchNormaliz (None, 40, 56, 56, 6 192         Conv3d_2b_1x1_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2b_1x1 (Activation)      (None, 40, 56, 56, 6 0           Conv3d_2b_1x1_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2c_3x3_conv (Conv3D)     (None, 40, 56, 56, 1 331776      Conv3d_2b_1x1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2c_3x3_bn (BatchNormaliz (None, 40, 56, 56, 1 576         Conv3d_2c_3x3_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_2c_3x3 (Activation)      (None, 40, 56, 56, 1 0           Conv3d_2c_3x3_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_3a_3x3 (MaxPooling3D) (None, 40, 28, 28, 1 0           Conv3d_2c_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1a_1x1_conv (Conv3D)  (None, 40, 28, 28, 9 18432       MaxPool2d_3a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2a_1x1_conv (Conv3D)  (None, 40, 28, 28, 1 3072        MaxPool2d_3a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1a_1x1_bn (BatchNorma (None, 40, 28, 28, 9 288         Conv3d_3b_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2a_1x1_bn (BatchNorma (None, 40, 28, 28, 1 48          Conv3d_3b_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1a_1x1 (Activation)   (None, 40, 28, 28, 9 0           Conv3d_3b_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2a_1x1 (Activation)   (None, 40, 28, 28, 1 0           Conv3d_3b_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_3b_3a_3x3 (MaxPooling (None, 40, 28, 28, 1 0           MaxPool2d_3a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_0a_1x1_conv (Conv3D)  (None, 40, 28, 28, 6 12288       MaxPool2d_3a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1b_3x3_conv (Conv3D)  (None, 40, 28, 28, 1 331776      Conv3d_3b_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2b_3x3_conv (Conv3D)  (None, 40, 28, 28, 3 13824       Conv3d_3b_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_3b_1x1_conv (Conv3D)  (None, 40, 28, 28, 3 6144        MaxPool2d_3b_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_0a_1x1_bn (BatchNorma (None, 40, 28, 28, 6 192         Conv3d_3b_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1b_3x3_bn (BatchNorma (None, 40, 28, 28, 1 384         Conv3d_3b_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2b_3x3_bn (BatchNorma (None, 40, 28, 28, 3 96          Conv3d_3b_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_3b_1x1_bn (BatchNorma (None, 40, 28, 28, 3 96          Conv3d_3b_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_0a_1x1 (Activation)   (None, 40, 28, 28, 6 0           Conv3d_3b_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_1b_3x3 (Activation)   (None, 40, 28, 28, 1 0           Conv3d_3b_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_2b_3x3 (Activation)   (None, 40, 28, 28, 3 0           Conv3d_3b_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3b_3b_1x1 (Activation)   (None, 40, 28, 28, 3 0           Conv3d_3b_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_3b (Concatenate)          (None, 40, 28, 28, 2 0           Conv3d_3b_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_3b_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_3b_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_3b_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1a_1x1_conv (Conv3D)  (None, 40, 28, 28, 1 32768       Mixed_3b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2a_1x1_conv (Conv3D)  (None, 40, 28, 28, 3 8192        Mixed_3b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1a_1x1_bn (BatchNorma (None, 40, 28, 28, 1 384         Conv3d_3c_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2a_1x1_bn (BatchNorma (None, 40, 28, 28, 3 96          Conv3d_3c_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1a_1x1 (Activation)   (None, 40, 28, 28, 1 0           Conv3d_3c_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2a_1x1 (Activation)   (None, 40, 28, 28, 3 0           Conv3d_3c_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_3c_3a_3x3 (MaxPooling (None, 40, 28, 28, 2 0           Mixed_3b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_0a_1x1_conv (Conv3D)  (None, 40, 28, 28, 1 32768       Mixed_3b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1b_3x3_conv (Conv3D)  (None, 40, 28, 28, 1 663552      Conv3d_3c_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2b_3x3_conv (Conv3D)  (None, 40, 28, 28, 9 82944       Conv3d_3c_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_3b_1x1_conv (Conv3D)  (None, 40, 28, 28, 6 16384       MaxPool2d_3c_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_0a_1x1_bn (BatchNorma (None, 40, 28, 28, 1 384         Conv3d_3c_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1b_3x3_bn (BatchNorma (None, 40, 28, 28, 1 576         Conv3d_3c_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2b_3x3_bn (BatchNorma (None, 40, 28, 28, 9 288         Conv3d_3c_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_3b_1x1_bn (BatchNorma (None, 40, 28, 28, 6 192         Conv3d_3c_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_0a_1x1 (Activation)   (None, 40, 28, 28, 1 0           Conv3d_3c_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_1b_3x3 (Activation)   (None, 40, 28, 28, 1 0           Conv3d_3c_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_2b_3x3 (Activation)   (None, 40, 28, 28, 9 0           Conv3d_3c_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_3c_3b_1x1 (Activation)   (None, 40, 28, 28, 6 0           Conv3d_3c_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_3c (Concatenate)          (None, 40, 28, 28, 4 0           Conv3d_3c_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_3c_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_3c_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_3c_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4a_3x3 (MaxPooling3D) (None, 20, 14, 14, 4 0           Mixed_3c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1a_1x1_conv (Conv3D)  (None, 20, 14, 14, 9 46080       MaxPool2d_4a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 7680        MaxPool2d_4a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1a_1x1_bn (BatchNorma (None, 20, 14, 14, 9 288         Conv3d_4b_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 48          Conv3d_4b_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1a_1x1 (Activation)   (None, 20, 14, 14, 9 0           Conv3d_4b_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4b_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4b_3a_3x3 (MaxPooling (None, 20, 14, 14, 4 0           MaxPool2d_4a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_0a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 92160       MaxPool2d_4a_3x3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1b_3x3_conv (Conv3D)  (None, 20, 14, 14, 2 539136      Conv3d_4b_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2b_3x3_conv (Conv3D)  (None, 20, 14, 14, 4 20736       Conv3d_4b_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_3b_1x1_conv (Conv3D)  (None, 20, 14, 14, 6 30720       MaxPool2d_4b_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_0a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 576         Conv3d_4b_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1b_3x3_bn (BatchNorma (None, 20, 14, 14, 2 624         Conv3d_4b_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2b_3x3_bn (BatchNorma (None, 20, 14, 14, 4 144         Conv3d_4b_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_3b_1x1_bn (BatchNorma (None, 20, 14, 14, 6 192         Conv3d_4b_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_0a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4b_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_1b_3x3 (Activation)   (None, 20, 14, 14, 2 0           Conv3d_4b_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_2b_3x3 (Activation)   (None, 20, 14, 14, 4 0           Conv3d_4b_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4b_3b_1x1 (Activation)   (None, 20, 14, 14, 6 0           Conv3d_4b_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4b (Concatenate)          (None, 20, 14, 14, 5 0           Conv3d_4b_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_4b_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_4b_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_4b_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 57344       Mixed_4b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2a_1x1_conv (Conv3D)  (None, 20, 14, 14, 2 12288       Mixed_4b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 336         Conv3d_4c_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2a_1x1_bn (BatchNorma (None, 20, 14, 14, 2 72          Conv3d_4c_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4c_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2a_1x1 (Activation)   (None, 20, 14, 14, 2 0           Conv3d_4c_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4c_3a_3x3 (MaxPooling (None, 20, 14, 14, 5 0           Mixed_4b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_0a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 81920       Mixed_4b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1b_3x3_conv (Conv3D)  (None, 20, 14, 14, 2 677376      Conv3d_4c_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2b_3x3_conv (Conv3D)  (None, 20, 14, 14, 6 41472       Conv3d_4c_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_3b_1x1_conv (Conv3D)  (None, 20, 14, 14, 6 32768       MaxPool2d_4c_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_0a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 480         Conv3d_4c_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1b_3x3_bn (BatchNorma (None, 20, 14, 14, 2 672         Conv3d_4c_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2b_3x3_bn (BatchNorma (None, 20, 14, 14, 6 192         Conv3d_4c_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_3b_1x1_bn (BatchNorma (None, 20, 14, 14, 6 192         Conv3d_4c_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_0a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4c_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_1b_3x3 (Activation)   (None, 20, 14, 14, 2 0           Conv3d_4c_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_2b_3x3 (Activation)   (None, 20, 14, 14, 6 0           Conv3d_4c_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4c_3b_1x1 (Activation)   (None, 20, 14, 14, 6 0           Conv3d_4c_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4c (Concatenate)          (None, 20, 14, 14, 5 0           Conv3d_4c_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_4c_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_4c_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_4c_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 65536       Mixed_4c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2a_1x1_conv (Conv3D)  (None, 20, 14, 14, 2 12288       Mixed_4c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 384         Conv3d_4d_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2a_1x1_bn (BatchNorma (None, 20, 14, 14, 2 72          Conv3d_4d_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4d_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2a_1x1 (Activation)   (None, 20, 14, 14, 2 0           Conv3d_4d_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4d_3a_3x3 (MaxPooling (None, 20, 14, 14, 5 0           Mixed_4c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_0a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 65536       Mixed_4c[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1b_3x3_conv (Conv3D)  (None, 20, 14, 14, 2 884736      Conv3d_4d_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2b_3x3_conv (Conv3D)  (None, 20, 14, 14, 6 41472       Conv3d_4d_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_3b_1x1_conv (Conv3D)  (None, 20, 14, 14, 6 32768       MaxPool2d_4d_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_0a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 384         Conv3d_4d_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1b_3x3_bn (BatchNorma (None, 20, 14, 14, 2 768         Conv3d_4d_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2b_3x3_bn (BatchNorma (None, 20, 14, 14, 6 192         Conv3d_4d_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_3b_1x1_bn (BatchNorma (None, 20, 14, 14, 6 192         Conv3d_4d_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_0a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4d_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_1b_3x3 (Activation)   (None, 20, 14, 14, 2 0           Conv3d_4d_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_2b_3x3 (Activation)   (None, 20, 14, 14, 6 0           Conv3d_4d_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4d_3b_1x1 (Activation)   (None, 20, 14, 14, 6 0           Conv3d_4d_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4d (Concatenate)          (None, 20, 14, 14, 5 0           Conv3d_4d_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_4d_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_4d_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_4d_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 73728       Mixed_4d[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2a_1x1_conv (Conv3D)  (None, 20, 14, 14, 3 16384       Mixed_4d[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 432         Conv3d_4e_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2a_1x1_bn (BatchNorma (None, 20, 14, 14, 3 96          Conv3d_4e_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4e_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2a_1x1 (Activation)   (None, 20, 14, 14, 3 0           Conv3d_4e_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4e_3a_3x3 (MaxPooling (None, 20, 14, 14, 5 0           Mixed_4d[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_0a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 57344       Mixed_4d[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1b_3x3_conv (Conv3D)  (None, 20, 14, 14, 2 1119744     Conv3d_4e_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2b_3x3_conv (Conv3D)  (None, 20, 14, 14, 6 55296       Conv3d_4e_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_3b_1x1_conv (Conv3D)  (None, 20, 14, 14, 6 32768       MaxPool2d_4e_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_0a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 336         Conv3d_4e_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1b_3x3_bn (BatchNorma (None, 20, 14, 14, 2 864         Conv3d_4e_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2b_3x3_bn (BatchNorma (None, 20, 14, 14, 6 192         Conv3d_4e_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_3b_1x1_bn (BatchNorma (None, 20, 14, 14, 6 192         Conv3d_4e_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_0a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4e_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_1b_3x3 (Activation)   (None, 20, 14, 14, 2 0           Conv3d_4e_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_2b_3x3 (Activation)   (None, 20, 14, 14, 6 0           Conv3d_4e_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4e_3b_1x1 (Activation)   (None, 20, 14, 14, 6 0           Conv3d_4e_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4e (Concatenate)          (None, 20, 14, 14, 5 0           Conv3d_4e_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_4e_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_4e_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_4e_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1a_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 84480       Mixed_4e[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2a_1x1_conv (Conv3D)  (None, 20, 14, 14, 3 16896       Mixed_4e[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1a_1x1_bn (BatchNorma (None, 20, 14, 14, 1 480         Conv3d_4f_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2a_1x1_bn (BatchNorma (None, 20, 14, 14, 3 96          Conv3d_4f_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1a_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4f_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2a_1x1 (Activation)   (None, 20, 14, 14, 3 0           Conv3d_4f_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_4f_3a_3x3 (MaxPooling (None, 20, 14, 14, 5 0           Mixed_4e[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_0a_1x1_conv (Conv3D)  (None, 20, 14, 14, 2 135168      Mixed_4e[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1b_3x3_conv (Conv3D)  (None, 20, 14, 14, 3 1382400     Conv3d_4f_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2b_3x3_conv (Conv3D)  (None, 20, 14, 14, 1 110592      Conv3d_4f_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_3b_1x1_conv (Conv3D)  (None, 20, 14, 14, 1 67584       MaxPool2d_4f_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_0a_1x1_bn (BatchNorma (None, 20, 14, 14, 2 768         Conv3d_4f_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1b_3x3_bn (BatchNorma (None, 20, 14, 14, 3 960         Conv3d_4f_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2b_3x3_bn (BatchNorma (None, 20, 14, 14, 1 384         Conv3d_4f_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_3b_1x1_bn (BatchNorma (None, 20, 14, 14, 1 384         Conv3d_4f_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_0a_1x1 (Activation)   (None, 20, 14, 14, 2 0           Conv3d_4f_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_1b_3x3 (Activation)   (None, 20, 14, 14, 3 0           Conv3d_4f_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_2b_3x3 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4f_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_4f_3b_1x1 (Activation)   (None, 20, 14, 14, 1 0           Conv3d_4f_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_4f (Concatenate)          (None, 20, 14, 14, 8 0           Conv3d_4f_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_4f_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_4f_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_4f_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_5a_2x2 (MaxPooling3D) (None, 10, 7, 7, 832 0           Mixed_4f[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1a_1x1_conv (Conv3D)  (None, 10, 7, 7, 160 133120      MaxPool2d_5a_2x2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2a_1x1_conv (Conv3D)  (None, 10, 7, 7, 32) 26624       MaxPool2d_5a_2x2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1a_1x1_bn (BatchNorma (None, 10, 7, 7, 160 480         Conv3d_5b_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2a_1x1_bn (BatchNorma (None, 10, 7, 7, 32) 96          Conv3d_5b_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1a_1x1 (Activation)   (None, 10, 7, 7, 160 0           Conv3d_5b_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2a_1x1 (Activation)   (None, 10, 7, 7, 32) 0           Conv3d_5b_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_5b_3a_3x3 (MaxPooling (None, 10, 7, 7, 832 0           MaxPool2d_5a_2x2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_0a_1x1_conv (Conv3D)  (None, 10, 7, 7, 256 212992      MaxPool2d_5a_2x2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1b_3x3_conv (Conv3D)  (None, 10, 7, 7, 320 1382400     Conv3d_5b_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2b_3x3_conv (Conv3D)  (None, 10, 7, 7, 128 110592      Conv3d_5b_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_3b_1x1_conv (Conv3D)  (None, 10, 7, 7, 128 106496      MaxPool2d_5b_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_0a_1x1_bn (BatchNorma (None, 10, 7, 7, 256 768         Conv3d_5b_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1b_3x3_bn (BatchNorma (None, 10, 7, 7, 320 960         Conv3d_5b_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2b_3x3_bn (BatchNorma (None, 10, 7, 7, 128 384         Conv3d_5b_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_3b_1x1_bn (BatchNorma (None, 10, 7, 7, 128 384         Conv3d_5b_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_0a_1x1 (Activation)   (None, 10, 7, 7, 256 0           Conv3d_5b_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_1b_3x3 (Activation)   (None, 10, 7, 7, 320 0           Conv3d_5b_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_2b_3x3 (Activation)   (None, 10, 7, 7, 128 0           Conv3d_5b_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5b_3b_1x1 (Activation)   (None, 10, 7, 7, 128 0           Conv3d_5b_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_5b (Concatenate)          (None, 10, 7, 7, 832 0           Conv3d_5b_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_5b_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_5b_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_5b_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1a_1x1_conv (Conv3D)  (None, 10, 7, 7, 192 159744      Mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2a_1x1_conv (Conv3D)  (None, 10, 7, 7, 48) 39936       Mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1a_1x1_bn (BatchNorma (None, 10, 7, 7, 192 576         Conv3d_5c_1a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2a_1x1_bn (BatchNorma (None, 10, 7, 7, 48) 144         Conv3d_5c_2a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1a_1x1 (Activation)   (None, 10, 7, 7, 192 0           Conv3d_5c_1a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2a_1x1 (Activation)   (None, 10, 7, 7, 48) 0           Conv3d_5c_2a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool2d_5c_3a_3x3 (MaxPooling (None, 10, 7, 7, 832 0           Mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_0a_1x1_conv (Conv3D)  (None, 10, 7, 7, 384 319488      Mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1b_3x3_conv (Conv3D)  (None, 10, 7, 7, 384 1990656     Conv3d_5c_1a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2b_3x3_conv (Conv3D)  (None, 10, 7, 7, 128 165888      Conv3d_5c_2a_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_3b_1x1_conv (Conv3D)  (None, 10, 7, 7, 128 106496      MaxPool2d_5c_3a_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_0a_1x1_bn (BatchNorma (None, 10, 7, 7, 384 1152        Conv3d_5c_0a_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1b_3x3_bn (BatchNorma (None, 10, 7, 7, 384 1152        Conv3d_5c_1b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2b_3x3_bn (BatchNorma (None, 10, 7, 7, 128 384         Conv3d_5c_2b_3x3_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_3b_1x1_bn (BatchNorma (None, 10, 7, 7, 128 384         Conv3d_5c_3b_1x1_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_0a_1x1 (Activation)   (None, 10, 7, 7, 384 0           Conv3d_5c_0a_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_1b_3x3 (Activation)   (None, 10, 7, 7, 384 0           Conv3d_5c_1b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_2b_3x3 (Activation)   (None, 10, 7, 7, 128 0           Conv3d_5c_2b_3x3_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d_5c_3b_1x1 (Activation)   (None, 10, 7, 7, 128 0           Conv3d_5c_3b_1x1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_5c (Concatenate)          (None, 10, 7, 7, 102 0           Conv3d_5c_0a_1x1[0][0]           \n",
      "                                                                 Conv3d_5c_1b_3x3[0][0]           \n",
      "                                                                 Conv3d_5c_2b_3x3[0][0]           \n",
      "                                                                 Conv3d_5c_3b_1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_avg_pool (AveragePooling (None, 9, 1, 1, 1024 0           Mixed_5c[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,294,544\n",
      "Trainable params: 12,279,984\n",
      "Non-trainable params: 14,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb304f",
   "metadata": {},
   "source": [
    "# Adding classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0dcefbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28a9a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sequential model\n",
    "model = models.Sequential()\n",
    "model.add(rgb_model)\n",
    "\n",
    "# Adding classification layers\n",
    "dropout_prob = 0.0\n",
    "\n",
    "model.add(Dropout(dropout_prob))\n",
    "model.add(Conv3D(NUM_CLASSES, (1, 1, 1), \n",
    "                 strides = (1, 1, 1), \n",
    "                padding = 'same',\n",
    "                use_bias = False,\n",
    "                name = 'Conv3d_6a_1x1'))\n",
    "\n",
    "num_frames_remaining = model.layers[-1].output_shape[1]\n",
    "\n",
    "model.add(Reshape((num_frames_remaining, NUM_CLASSES)))\n",
    "\n",
    "model.add(Lambda(lambda x: K.mean(x, axis=1, keepdims=False),\n",
    "                   output_shape=lambda s: (s[0], s[2])))\n",
    "\n",
    "model.add(Activation('softmax', name = 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f62f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in rgb_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba44ce85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "i3d_inception (Functional)   (None, 9, 1, 1, 1024)     12294544  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 1, 1, 1024)     0         \n",
      "_________________________________________________________________\n",
      "Conv3d_6a_1x1 (Conv3D)       (None, 9, 1, 1, 2)        2048      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 9, 2)              0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "prediction (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 12,296,592\n",
      "Trainable params: 2,048\n",
      "Non-trainable params: 12,294,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49125e",
   "metadata": {},
   "source": [
    "# Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3aa68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f9c9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "    Args: \n",
    "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "        batch_size: the number of data points in each batch\n",
    "        shuffle: whether to shuffle the data per epoch\n",
    "    Note:\n",
    "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True, \n",
    "                 target_frames = 79, crop_dim = (224, 224), seed = None):\n",
    "        # Initialize the params\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.data_aug = data_augmentation\n",
    "        self.target_frames = target_frames\n",
    "        self.seed = seed\n",
    "        self.crop_dim = crop_dim\n",
    "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "        self.X_path, self.Y_dict = self.search_data() \n",
    "        # Print basic statistics information\n",
    "        self.print_stats()\n",
    "        return None\n",
    "    \n",
    "    def search_data(self):\n",
    "        X_path = []\n",
    "        Y_dict = {}\n",
    "        # list all kinds of sub-folders\n",
    "        self.dirs = sorted(os.listdir(self.directory))\n",
    "        one_hots = np_utils.to_categorical(range(len(self.dirs)))\n",
    "        for i,folder in enumerate(self.dirs):\n",
    "            folder_path = os.path.join(self.directory,folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path,file)\n",
    "                # append the each file path, and keep its label  \n",
    "                X_path.append(file_path)\n",
    "                Y_dict[file_path] = one_hots[i]\n",
    "        return X_path, Y_dict\n",
    "    \n",
    "    def print_stats(self):\n",
    "        # calculate basic information\n",
    "        self.n_files = len(self.X_path)\n",
    "        self.n_classes = len(self.dirs)\n",
    "        self.indexes = np.arange(len(self.X_path))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        # Output states\n",
    "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "        for i,label in enumerate(self.dirs):\n",
    "            print('%10s : '%(label),i)\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        # calculate the iterations of each epoch\n",
    "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "        return int(steps_per_epoch)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the data of each batch\n",
    "        \"\"\"\n",
    "        # get the indexs of each batch\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # using batch_indexs to get path of current batch\n",
    "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "        # get batch data\n",
    "        batch_x, batch_y = self.data_generation(batch_path)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # shuffle the data at each end of epoch\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def data_generation(self, batch_path):\n",
    "        # load data into memory, you can change the np.load to any method you want        \n",
    "        batch_x = [self.load_data(x) for x in batch_path]\n",
    "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "        # transfer the data format and take one-hot coding for labels\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def dynamic_crop(self, video):\n",
    "        video_dim = video.shape\n",
    "        video_width = video_dim[2]\n",
    "        video_height = video_dim[3]\n",
    "        \n",
    "        if self.data_aug:\n",
    "            x_max = video_width - self.crop_dim[0]\n",
    "            y_max = video_height - self.crop_dim[1]\n",
    "\n",
    "            x = random.randint(0, x_max)\n",
    "            y = random.randint(0, y_max)\n",
    "            \n",
    "        else:\n",
    "            x_center = math.ceil(video_width/2)\n",
    "            y_center = math.ceil(video_height/2)\n",
    "            \n",
    "            x = x_center - math.ceil(self.crop_dim[0]/2)\n",
    "            y = y_center - math.ceil(self.crop_dim[1]/2)\n",
    "                        \n",
    "        return video[:,:,x:x+self.crop_dim[0],y:y+self.crop_dim[1],:]\n",
    "        \n",
    "    \n",
    "    def frame_sampling(self, video):\n",
    "        # get total frames of input video\n",
    "        len_frames = video.shape[1]\n",
    "        \n",
    "        # If the video is shorter than needed\n",
    "        if len_frames < self.target_frames:\n",
    "            # Times the video need to be looped to get 64 frames\n",
    "            times = self.target_frames//len_frames\n",
    "            remainder = self.target_frames%len_frames\n",
    "            # Creating new array to store cat video\n",
    "            new_video = video\n",
    "            \n",
    "            # Repeat the video as many times as needed\n",
    "            for n in range(1,times):\n",
    "                new_video = np.concatenate((new_video, video), axis = 1)\n",
    "            # Add part of the video if needed\n",
    "            if remainder > 0:\n",
    "                new_video = np.concatenate((new_video, video[:,:remainder,:,:]), axis = 1)\n",
    "            \n",
    "            return new_video\n",
    "        \n",
    "        # If the video is longer than needed\n",
    "        elif len_frames > self.target_frames:\n",
    "            # Set random start\n",
    "            start_frame = random.randint(0,len_frames - self.target_frames)\n",
    "            end_frame = start_frame + self.target_frames\n",
    "            \n",
    "            new_video = video[:,start_frame:end_frame,:,:]\n",
    "            \n",
    "            return new_video\n",
    "        \n",
    "        # If the video is fine\n",
    "        elif len_frames == self.target_frames:\n",
    "            return video\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        data = np.load(path)['arr_0']\n",
    "    \n",
    "        # Sampling frames\n",
    "        if self.target_frames is not None:\n",
    "            data = self.frame_sampling(video = data)\n",
    "            \n",
    "        data = self.dynamic_crop(data)\n",
    "\n",
    "        return data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b93f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "path_train = '../datai3d/rgb/train/'\n",
    "path_val = '../datai3d/rgb/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28c5db75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1207 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Found 393 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n"
     ]
    }
   ],
   "source": [
    "train_generator = DataGenerator(directory=path_train, \n",
    "                                batch_size=batch_size, \n",
    "                                data_augmentation=True)\n",
    "\n",
    "validation_generator = DataGenerator(directory=path_val, \n",
    "                                batch_size=batch_size, \n",
    "                                data_augmentation=False)\n",
    "                                #target_frames = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6d3dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = validation_generator.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0f5b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7755c15",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4a0ac6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 100\n",
    "steps_per_epoch = train_generator.n_files//batch_size\n",
    "validation_steps = validation_generator.n_files//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c584fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "filepath = 'checkpoints/weights_i3drgb.hdf5'\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                 factor=0.1,\n",
    "                                                 patience=5, \n",
    "                                                 min_lr=0.001,\n",
    "                                                verbose = 1)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=1, \n",
    "                                                save_best_only=True, \n",
    "                                                save_weights_only=False, \n",
    "                                                mode='auto', \n",
    "                                                save_freq='epoch')\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                             restore_best_weights = True, \n",
    "                                             patience = 10, \n",
    "                                             min_delta = 0.01,\n",
    "                                            verbose = 1)\n",
    "\n",
    "callbacks = [reduce_lr, checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2913103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='CategoricalCrossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d93fdf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[8,40,112,112,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_2/i3d_inception/Conv3d_1a_7x7_conv/Conv3D (defined at <ipython-input-87-b2b390ed09ed>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_22619]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-b2b390ed09ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8,40,112,112,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_2/i3d_inception/Conv3d_1a_7x7_conv/Conv3D (defined at <ipython-input-87-b2b390ed09ed>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_22619]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_steps,\n",
    "    callbacks = callbacks,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ae28303",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643eb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
